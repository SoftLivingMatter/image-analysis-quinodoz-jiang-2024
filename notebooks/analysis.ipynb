{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a28cd-0c97-4249-be9c-2c81d26eec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66618d-99d1-47f6-912f-35fa5d4e8fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to add total intensity by multiplying the area with the intensity\n",
    "def add_total_intens(df, channels, name):\n",
    "    if isinstance(channels, str):\n",
    "        channels = [channels]\n",
    "    for channel in channels:\n",
    "        df[f'total_intens_{channel}_{name}'] = df[f'Intensity_MeanIntensity_{channel}'] * df['AreaShape_Area']\n",
    "    return df\n",
    "\n",
    "# helper function to merge incoming dfs with the results by image number and cell number.  Can change reduction to be count, sum, etc.\n",
    "# map cols renames the columns from the input to output DFs\n",
    "def merge_reduced(result_df, df, map_cols, reduction, how='inner'):\n",
    "    return result_df.merge(\n",
    "        df.groupby(['ImageNumber', 'Parent_DilatedGC'])[list(map_cols.keys())].aggregate(reduction).reset_index().rename(columns=map_cols),\n",
    "        on=['ImageNumber', 'Parent_DilatedGC'],\n",
    "        how=how,\n",
    "    )\n",
    "\n",
    "def build_initial_data(directory, common, regex):\n",
    "    gc = pd.read_csv(\n",
    "        directory / 'InitialGC.csv', \n",
    "        usecols=common,\n",
    "    )\n",
    "    \n",
    "    # read image metadata, mainly file location\n",
    "    images = pd.read_csv(directory / 'Image.csv', usecols=['Metadata_FileLocation', 'ImageNumber', 'Metadata_Series'])\n",
    "    \n",
    "    # add in regex of filename (time, treatment, etc)\n",
    "    if regex:\n",
    "        images = images.join(images['Metadata_FileLocation'].str.extract(regex))\n",
    "    \n",
    "    # start building the final result, with image number and merged_gc number (renamed to cell number)\n",
    "    result = gc[['ImageNumber', 'Parent_DilatedGC']].drop_duplicates().rename(columns={\n",
    "        'Parent_DilatedGC': 'CellNumber'\n",
    "    })\n",
    "    \n",
    "    # add image file location and regex info\n",
    "    result = result.merge(images, on='ImageNumber', how=\"left\")\n",
    "    \n",
    "    # gc number, done separately because the cellnumber doesn't match parent_DilatedGC any more\n",
    "    result = result.merge(\n",
    "        gc.groupby(['ImageNumber', 'Parent_DilatedGC'])['AreaShape_Area'].count().rename('Count_GC').reset_index(),\n",
    "        left_on=['ImageNumber', 'CellNumber'], right_on=['ImageNumber', 'Parent_DilatedGC']\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_initial_gc(result, directory, common, dfc_intens=False):\n",
    "    # read GC, plus intensities for GC and Probe and eccentricity\n",
    "    gc = pd.read_csv(\n",
    "        directory / 'InitialGC.csv', \n",
    "        usecols=common + ['Intensity_MeanIntensity_GC', 'Intensity_MeanIntensity_Probe', \n",
    "                          'AreaShape_Eccentricity', 'AreaShape_Perimeter',\n",
    "                          'Location_CenterMassIntensity_X_GC',  'Location_CenterMassIntensity_Y_GC',\n",
    "                         ] + (['Intensity_MeanIntensity_DFC',] if dfc_intens else []),\n",
    "    )\n",
    "    \n",
    "    # gc intensity in gc  -> may not be the same, normalize to control in each folder\n",
    "    gc = add_total_intens(gc, ['GC', 'Probe']+ (['DFC',] if dfc_intens else []), 'GC')\n",
    "    \n",
    "    # calculate circularity as 4 pi area / perimeter ** 2\n",
    "    gc['AreaShape_Cicularity'] = 4 * np.pi * gc['AreaShape_Area'] / gc['AreaShape_Perimeter'] ** 2\n",
    "    \n",
    "    # gc shape and size\n",
    "    map_cols = {\n",
    "        'AreaShape_Eccentricity': 'mean_GC_eccentricity',\n",
    "        'AreaShape_Cicularity': 'mean_GC_circularity',\n",
    "        'Location_CenterMassIntensity_X_GC': 'center_x',\n",
    "        'Location_CenterMassIntensity_Y_GC': 'center_y',\n",
    "    }\n",
    "    result = merge_reduced(result, gc, map_cols, 'mean')\n",
    "    map_cols = {\n",
    "        'total_intens_GC_GC': 'total_GC_intens',\n",
    "        'total_intens_Probe_GC': 'total_Probe_intens_GC',\n",
    "        'AreaShape_Area': 'GC_area',\n",
    "    }\n",
    "    if dfc_intens:\n",
    "        map_cols['total_intens_DFC_GC'] = 'total_DFC_intens_GC'\n",
    "    result = merge_reduced(result, gc, map_cols, 'sum')\n",
    "    result['mean_mean_GC_intens'] = result['total_GC_intens']/ result['GC_area']\n",
    "    result['mean_mean_Probe_intens'] = result['total_Probe_intens_GC']/ result['GC_area']\n",
    "    if dfc_intens:\n",
    "        result['mean_mean_DFC_intens'] = result['total_DFC_intens_GC']/ result['GC_area']\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_initial_fc(result, directory, common):\n",
    "    # read FC intensities, positions (not used yet) and number of children in each region.\n",
    "    fc = pd.read_csv(\n",
    "        directory / 'InitialFC.csv', \n",
    "        usecols=common + ['Intensity_MeanIntensity_FC', 'Intensity_MeanIntensity_Probe', \n",
    "                          'Location_CenterMassIntensity_X_FC', 'Location_CenterMassIntensity_Y_FC',],\n",
    "    )\n",
    "    \n",
    "    # fc intensity in fc\n",
    "    # size of fc\n",
    "    fc = add_total_intens(fc, ['FC', 'Probe'], 'FC')\n",
    "\n",
    "    # add fcs total\n",
    "    result = merge_reduced(result, fc, {\"AreaShape_Area\": \"Count_FC\"}, 'count')\n",
    "    \n",
    "    map_cols = {\n",
    "        'total_intens_FC_FC': 'total_FC_intens',\n",
    "        'total_intens_FC_FC': 'total_Probe_intens_FC',\n",
    "        'AreaShape_Area': 'FC_area',\n",
    "    }\n",
    "    result = merge_reduced(result, fc, map_cols, 'sum')\n",
    "    result['FC_density'] = result['Count_FC']/ result['GC_area']\n",
    "\n",
    "    # add fcs outside of GC\n",
    "    fc = pd.read_csv(\n",
    "        directory / 'ExtraNucleolarFCs.csv', \n",
    "        usecols=common,\n",
    "    )\n",
    "    result = merge_reduced(result, fc, {\"AreaShape_Area\": \"Count_Nucleoplasmic_FC\"}, 'count', how='left')\n",
    "    result.loc[result['Count_Nucleoplasmic_FC'].isna(), 'Count_Nucleoplasmic_FC'] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_rim(result, directory, common, dfc, bins=1, total=10):\n",
    "    cols = open(directory / 'InitialGC.csv').readline().split(',')\n",
    "    cols = [c for c in cols \n",
    "            if c.startswith('RadialDistribution_FracAtD')\n",
    "            # or c.startswith('RadialDistribution_MeanFrac')\n",
    "           ]\n",
    "    distributions = pd.read_csv(\n",
    "        directory / 'InitialGC.csv', \n",
    "        usecols=common + (cols if dfc else [c for c in cols if 'DFC' not in c]),\n",
    "    )\n",
    "\n",
    "    bins = [i for i in range(total, total-bins, -1)]\n",
    "    relative_areas = distributions[[f'RadialDistribution_FracAtD_GCObjectImage_{bin}of{total}' for bin in bins]].sum(axis=1)\n",
    "    distributions['fc_rim_enrichment'] = distributions[[f'RadialDistribution_FracAtD_FC_{bin}of{total}' for bin in bins]].sum(axis=1) / relative_areas\n",
    "    if dfc:\n",
    "        distributions['dfc_rim_enrichment'] = distributions[[f'RadialDistribution_FracAtD_DFC_{bin}of{total}' for bin in bins]].sum(axis=1) / relative_areas\n",
    "\n",
    "    # print(dists[[f'RadialDistribution_MeanFrac_DFC_{bin}of10' for bin in bins]].sum(axis=1))\n",
    "    # print(relative_areas)\n",
    "        \n",
    "    map_cols = {\n",
    "        'fc_rim_enrichment': 'fc_rim_enrichment',\n",
    "        'dfc_rim_enrichment': 'dfc_rim_enrichment',\n",
    "    } if dfc else {'fc_rim_enrichment': 'fc_rim_enrichment'}\n",
    "    result = merge_reduced(result, distributions, map_cols, 'mean')\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_correlation(result, directory, common):\n",
    "    # correlations over combined regions\n",
    "    cols = open(directory / 'CombinedObjects.csv').readline().split(',')\n",
    "    cols = [c for c in cols \n",
    "            if c.startswith('Correlation_Correlation')\n",
    "            or c.startswith('Correlation_Overlap')\n",
    "           ]\n",
    "    corr = pd.read_csv(\n",
    "        directory / 'CombinedObjects.csv', \n",
    "        usecols=common + cols,\n",
    "    )\n",
    "    \n",
    "    # multiply all correlations by area\n",
    "    corr[cols] *= corr['AreaShape_Area'].to_numpy()[:, None]\n",
    "    \n",
    "    # sum and add to result\n",
    "    map_cols = {c: c[12:] for c in cols}\n",
    "    # map_cols = {c: c for c in cols}\n",
    "    map_cols['AreaShape_Area'] = 'combined_area'\n",
    "    result = merge_reduced(result, corr, map_cols, 'sum')\n",
    "    \n",
    "    # divide by total area for correlation\n",
    "    result[[c for c in map_cols.values() if c != 'combined_area']] /= result['combined_area'].to_numpy()[:, None]\n",
    "    return result\n",
    "    \n",
    "def read_data(directory, regex=None, dfc=True, bins=4, dfc_intens=False):\n",
    "    directory = Path(directory)\n",
    "    # image and object number are uniuqe identifiers.  Area is used a lot and the parent_mergedGC should corresopnd to a single cell\n",
    "    common = ['ImageNumber', 'ObjectNumber', 'AreaShape_Area', 'Parent_DilatedGC']\n",
    "\n",
    "    result = build_initial_data(directory, common, regex)\n",
    "    \n",
    "    result = add_initial_gc(result, directory, common, dfc_intens)\n",
    "    \n",
    "    result = add_initial_fc(result, directory, common)\n",
    "    \n",
    "    result = add_rim(result, directory, common, dfc, bins, total=20)\n",
    "    \n",
    "    result = add_correlation(result, directory, common)\n",
    "    \n",
    "    return result.drop(columns='Parent_DilatedGC')\n",
    "    # fc position (stringyness?, graph morphology of fcs)\n",
    "\n",
    "full_data = read_data('morphology/240820_FISH/outputs', r'/.*_10A_(?P<probe>[^_0]+)(?:\\d{3}\\d?)?.nd2', bins=4)\n",
    "full_data.loc[full_data.isna().any(axis=1), 'Metadata_FileLocation'].unique()\n",
    "full_data.probe.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae613a-c2fc-408d-957d-db2fd4078837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## mising Fib data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0a46e-4027-4f76-b85f-cb0711e01f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('morphology/Fib_15c_control/outputs', r'/[A-G]\\d+_MCF10A(?P<treatment>FibKD|ctl)_30p(?P<time>\\d+)c.*nd2').assign(exp='Fib')\n",
    "data.to_csv('fib_15c_control.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052a49f-5ab8-4e54-8d3e-a7e831260fca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initial analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f1925-330d-4033-8603-54e3d316e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read_data('morphology/CX_EU/outputs', r'/10A_(?P<treatment>CX|ctl)_15p(?P<time>\\d+)c.*nd2', dfc=False)\n",
    "\n",
    "dat.loc[dat.isna().any(axis=1), 'Metadata_FileLocation'].unique()\n",
    "# dat['Metadata_FileLocation'].unique()\n",
    "# dat.loc[dat.isna().any(axis=1)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66b821-e664-4e76-8d1a-d8e8d3b2e907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to parse out 5' ETS from CX\n",
    "cx = read_data('morphology/CX/outputs', r'/[A-G]\\d+_(?P<treatment>CX)(?P<time>\\d+)min_(?P<probe>Junction1|18S|45S|Junction2|Junction4|ITS1|28S).*nd2').assign(exp='CX')\n",
    "missing = cx.isna().any(axis=1)\n",
    "parsed = cx.loc[missing, 'Metadata_FileLocation'].str.extract(r'/.*ETS_CX(?P<time>\\d+)min.*nd2')\n",
    "cx.loc[missing, 'treatment'] = 'CX'\n",
    "cx.loc[missing, 'probe'] = '5ETS'\n",
    "cx.loc[missing, 'time'] = parsed['time']\n",
    "most_data = pd.concat([\n",
    "    cx,\n",
    "    read_data('morphology/Fib/outputs', r'/[A-G]\\d+_MCF10A(?P<treatment>FibKD|ctl)_30p(?P<time>\\d+)c.*nd2').assign(exp='Fib'),\n",
    "    read_data('morphology/FVP_FISH/outputs', r'/[A-G]\\d+_(?P<treatment>FVP)(?P<time>\\d+)min_.*_(?P<probe>Junction1|18S|45S|Junction2|Junction4|ITS1|28S|3ETStile|ITS2b).*nd2').assign(exp='FVP_FISH'),\n",
    "    read_data('morphology/FVP_EU/outputs', r'/[A-G]\\d+_(?P<treatment>FVP|DMSO)_15p(?P<time>\\d+)c.*nd2').assign(exp='FVP_EU'),\n",
    "    read_data('morphology/RPL5/outputs', r'/[A-G]\\d+_(?P<treatment>SCR|RPL5KD)_15p(?P<time>\\d+)c.*nd2').assign(exp='RPL5'),\n",
    "    read_data('morphology/RPL5_FISH/outputs', r'/[A-G]\\d+_(?P<treatment>RPL5KD|SCR)_(?P<probe>Junction1|18S|45S|Junction2|Junction4|ITS1|28S|3ETStile|ITS2b|5ETS|5S|Junction3).*nd2').assign(exp='RPL5_FISH'),\n",
    "    read_data('morphology/U3U8_EU/outputs', r'/[A-G]\\d+__?(?P<treatment>U3ASO|ctlASO|U8ASO)_15p(?P<time>\\d+)c.*nd2').assign(exp='U3U8_EU'),\n",
    "    read_data('morphology/U3U8/outputs', r'/[A-G]\\d+_(?P<treatment>U3ASO|SCR|U8ASO)_(?P<probe>U3FISH|U8FISH).*nd2').assign(exp='U3U8'),\n",
    "    read_data('morphology_nodfc/FVP_nodfc/outputs', r'/[A-G]\\d+_(?P<treatment>DMSO|FVP2uM)_15p(?P<time>\\d+)c.*nd2', dfc=False).assign(exp='FVP_nodfc'),\n",
    "    read_data('morphology/CX_EU/outputs', r'/10A_(?P<treatment>CX|ctl)_15p(?P<time>\\d+)c.*nd2').assign(exp='CX_EU'),\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9bbef-22ee-4d7c-815c-a52374296d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_data = most_data\n",
    "full_data['time'] = full_data['time'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512cb933-4933-4c77-84ba-86e9268462c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_data.to_csv('morphology.csv', index=False)\n",
    "full_data.groupby(['exp', 'treatment']).Count_GC.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283632b3-3f27-4b2b-b54c-c6cc7eb9c1b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Look at untreated cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa0e62-6ce3-4332-ba7c-54ea2f0731bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.treatment.isin(('DMSO', 'SCR', 'ctlASO', 'ctl',))].copy()\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not c.startswith('filename') \n",
    "          and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'exp']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='exp', ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc1bb1-5f73-41b4-9b7d-4cc4c1bc7bda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7728fe6-0404-4292-b568-5b1a10058e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'CX'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='time', ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5252cd-7121-45af-9333-884ef24a2d9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CX EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b2ee0-eff7-4e94-8b96-87dd8bb4e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'CX_EU'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FibKD', 'ctl'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "# sns.lineplot(data=df, x='time', y='RWC_FC_Probe', label='FC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_DFC_Probe', label='DFC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_GC_Probe', label='GC_Probe', style='treatment', legend=False)\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_CX.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f4546-60c3-472f-8cc9-ffb195a29071",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23df8c-f476-4abd-8bde-49163889f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'Fib'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FibKD', 'ctl'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "# sns.lineplot(data=df, x='time', y='RWC_FC_Probe', label='FC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_DFC_Probe', label='DFC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_GC_Probe', label='GC_Probe', style='treatment', legend=False)\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_fib.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d14053-e6b6-4cad-8514-4defeaf92fe3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FVP EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0826efe-267f-425a-863d-309ca3952c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'FVP_EU'].copy()\n",
    "# drop some data from another experiment...\n",
    "df = df[~df.time.isna()]\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FVP', 'DMSO'), ('-', 'dotted')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_fvp.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16840277-865c-4fc1-84c2-099b806e15a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FVP no DFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66fd7a-abff-466c-974d-396df5e010c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'FVP_nodfc'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'DFC' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FVP2uM', 'DMSO'), ('-', 'dotted')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_fvp_nodfc.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ea96f-1cd8-4358-a490-1df6eb59079a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FVP FISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b8494-baf7-499f-beea-31a1c15cdce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'FVP_FISH'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FVP', 'DMSO'), ('-', 'dotted')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='probe')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='probe')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='probe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef81257-d0d1-434e-8b04-e1baaa11b355",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## RPL5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bcba2-140f-45ae-b2e8-d5876fc0f3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'RPL5'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('RPL5KD', 'SCR'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "# sns.lineplot(data=df, x='time', y='RWC_FC_Probe', label='FC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_DFC_Probe', label='DFC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_GC_Probe', label='GC_Probe', style='treatment', legend=False)\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_rpl5.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52449b2-329c-4142-b95b-cd5bbbdf73e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## RPL5_FISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e17f42-931c-4f42-a73d-b6d5e30c3075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'RPL5_FISH'].copy()\n",
    "df\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('RPL5KD', 'SCR'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='probe', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.barplot(data=df, x='probe', y='Correlation_FC_Probe', hue='treatment')\n",
    "plt.xticks(rotation=60)\n",
    "fig, axes = plt.subplots()\n",
    "sns.barplot(data=df, x='probe', y='Correlation_DFC_Probe', hue='treatment')\n",
    "plt.xticks(rotation=60)\n",
    "fig, axes = plt.subplots()\n",
    "sns.barplot(data=df, x='probe', y='Correlation_GC_Probe', hue='treatment')\n",
    "plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad44ac-8649-464f-82c4-7bbe302e4d1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## U8 with FISH probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1c135-fc91-429d-b807-c171736b82fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.probe == 'U8FISH'].copy()\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          # and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "df = df[(df.mean_mean_Probe_intens < 0.002) | (df.treatment == 'SCR')]\n",
    "print(df.groupby(['exp', 'treatment', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='treatment', ax=ax)\n",
    "    \n",
    "fig, axes = plt.subplots()\n",
    "sns.ecdfplot(data=df[df.treatment != 'SCR'], x='mean_mean_Probe_intens', hue='treatment', ax=axes)\n",
    "axes.set_xlim(0, 0.0025)\n",
    "fig, axes = plt.subplots()\n",
    "# sns.kdeplot(data=df, x='dfc_rim_enrichment', hue='treatment', ax=axes)\n",
    "sns.ecdfplot(data=df, x='dfc_rim_enrichment', hue='treatment', ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131baade-a4f5-47e2-9353-e90d65ac75f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## U3 with FISH probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeb102-a191-479d-9e2b-45bfd052d847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.probe == 'U3FISH'].copy()\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          # and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "df = df[(df.mean_mean_Probe_intens < 0.005) | (df.treatment == 'SCR')]\n",
    "print(df.groupby(['exp', 'treatment', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='treatment', ax=ax)\n",
    "    \n",
    "fig, axes = plt.subplots()\n",
    "sns.ecdfplot(data=df[df.treatment != 'SCR'], x='mean_mean_Probe_intens', hue='treatment', ax=axes)\n",
    "fig, axes = plt.subplots()\n",
    "sns.ecdfplot(data=df, x='fc_rim_enrichment', hue='treatment', ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0263a-bdaa-4afc-a6a3-4dd596a748a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## U3 U8 EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292bb473-ace1-49c0-9ba1-25bf03fc91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'U3U8_EU'].copy()\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          # and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='treatment', ax=ax)\n",
    "\n",
    "plt.subplots()\n",
    "sns.kdeplot(data=df, x='fc_rim_enrichment', hue='treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f44872-3c3b-4672-96a1-10231dc98b46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Normalize each experiment by the \"control\" means\n",
    "\n",
    "- CX t=0 is no treatment and t=120 is 2hr treatment so it makes sense to compare them - should give you the biggest changes\n",
    "- For RPL5, all time points should have equal morphology changes - you can average all time points for morphology measurement (or maybe pick one time point if enough cells and if different time points look close enough) but for the probe channel which is EU, we need its correlation with GC overtime (edited) \n",
    "- FVP has a pretreatment of 1hr and morph progress with time, for morph purpose, can pick one time point and compare DMSO vs FVP? Like the 60min time point  (edited) \n",
    "- U3 and U8 should be two separate dataset, and SCR can be divided into two based on whether it belongs to U3 or U8.  Threshold for knockdown 0.002 for U8, 0.005 for U3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6aa6a-3a79-4243-9c94-302dc16c13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.exp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91e2c9-6728-410a-9082-dbcbf768e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by control fold change\n",
    "toplot = [c for c in full_data.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "\n",
    "def normalize(df, experiment, columns, loc_col, control, treated):\n",
    "    df = df[df.exp == experiment].copy()\n",
    "    df.loc[df[loc_col] == treated, columns] = df.loc[df[loc_col] == treated, columns] / df.loc[df[loc_col] == control, columns].mean()\n",
    "    return df[df[loc_col] == treated]\n",
    "\n",
    "normalized = pd.concat([\n",
    "    normalize(full_data, 'CX', toplot, 'time', 0, 120),\n",
    "    normalize(full_data, 'Fib', toplot, 'treatment', 'ctl', 'FibKD'),\n",
    "    normalize(full_data[full_data.time == 15], \n",
    "              'FVP_EU', toplot, 'treatment', 'DMSO', 'FVP'),\n",
    "    normalize(full_data[(full_data.probe == 'U3FISH') & ((full_data.mean_mean_Probe_intens < 0.005) | (full_data.treatment == 'SCR'))], \n",
    "              'U3U8', toplot, 'treatment', 'SCR', 'U3ASO').assign(exp='U3'),\n",
    "    normalize(full_data[(full_data.probe == 'U8FISH') & ((full_data.mean_mean_Probe_intens < 0.002) | (full_data.treatment == 'SCR'))], \n",
    "              'U3U8', toplot, 'treatment', 'SCR', 'U8ASO').assign(exp='U8'),\n",
    "    normalize(full_data, 'RPL5', toplot, 'treatment', 'SCR', 'RPL5KD'),\n",
    "],\n",
    "    ignore_index=True)\n",
    "normalized.to_csv('normalized_fold.csv', index=False)\n",
    "\n",
    "# df = full_data[(full_data.exp == 'U3U8') & (full_data.probe == 'U3FISH') & ((full_data.mean_mean_Probe_intens < 0.005) | (full_data.treatment == 'SCR'))].copy()\n",
    "# df.loc[df.treatment == 'FVP2uM', toplot] = np.log2(df.loc[df.treatment == 'FVP2uM', toplot] / df.loc[df.treatment == 'DMSO', toplot].mean())\n",
    "# df = df[df.treatment == 'FVP2uM']\n",
    "# df\n",
    "\n",
    "normalized.exp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f5867-95ac-40ae-b74f-89bb232f1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by control z scores\n",
    "toplot = [c for c in full_data.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "\n",
    "def normalize(df, experiment, columns, loc_col, control, treated):\n",
    "    df = df[df.exp == experiment].copy()\n",
    "    cntr = df.loc[df[loc_col] == control, columns]\n",
    "    df.loc[df[loc_col] == treated, columns] = (df.loc[df[loc_col] == treated, columns] - cntr.mean()) / cntr.std()\n",
    "    return df[df[loc_col] == treated]\n",
    "\n",
    "normalized = pd.concat([\n",
    "    normalize(full_data, 'CX', toplot, 'time', 0, 120),\n",
    "    normalize(full_data, 'Fib', toplot, 'treatment', 'ctl', 'FibKD'),\n",
    "    normalize(full_data[full_data.time == 15], \n",
    "              'FVP_EU', toplot, 'treatment', 'DMSO', 'FVP'),\n",
    "    normalize(full_data[(full_data.probe == 'U3FISH') & ((full_data.mean_mean_Probe_intens < 0.005) | (full_data.treatment == 'SCR'))], \n",
    "              'U3U8', toplot, 'treatment', 'SCR', 'U3ASO').assign(exp='U3'),\n",
    "    normalize(full_data[(full_data.probe == 'U8FISH') & ((full_data.mean_mean_Probe_intens < 0.002) | (full_data.treatment == 'SCR'))], \n",
    "              'U3U8', toplot, 'treatment', 'SCR', 'U8ASO').assign(exp='U8'),\n",
    "    normalize(full_data, 'RPL5', toplot, 'treatment', 'SCR', 'RPL5KD'),\n",
    "],\n",
    "    ignore_index=True)\n",
    "normalized.to_csv('normalized_z.csv', index=False)\n",
    "\n",
    "# df = full_data[(full_data.exp == 'U3U8') & (full_data.probe == 'U3FISH') & ((full_data.mean_mean_Probe_intens < 0.005) | (full_data.treatment == 'SCR'))].copy()\n",
    "# df.loc[df.treatment == 'FVP2uM', toplot] = np.log2(df.loc[df.treatment == 'FVP2uM', toplot] / df.loc[df.treatment == 'DMSO', toplot].mean())\n",
    "# df = df[df.treatment == 'FVP2uM']\n",
    "# df\n",
    "\n",
    "normalized.exp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cce89-cac4-42cc-8af1-769e93b15d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[full_data.exp == 'FVP_EU'].groupby(['treatment', 'time']).Count_FC.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da39372-b5f3-4525-a3e1-5a0a271e8d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=normalized, x=col, hue='exp', ax=ax)\n",
    "    \n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.violinplot(data=normalized, y=col, x='exp', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569c61f-4910-40ea-b40c-ebbb0ee3fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = dict(zip(normalized.exp.unique(), sns.color_palette()))\n",
    "row_colors = normalized.exp.map(lut)\n",
    "# dat = normalized.groupby('exp')[toplot].median(numeric_only=False).dropna(axis=1).T\n",
    "# dat = np.log2(normalized.groupby('exp')[toplot].median(numeric_only=False)).replace(-np.inf, np.nan).dropna(axis=1).T\n",
    "# dat /= (dat.abs().to_numpy()).max(axis=1, keepdims=True)\n",
    "sns.clustermap(\n",
    "    # np.log2(normalized.groupby('exp')[toplot].mean(numeric_only=False)).dropna(axis=1).T,\n",
    "    # np.log2(normalized.groupby('exp')[toplot].median(numeric_only=False)).replace(-np.inf, np.nan).dropna(axis=1).T,\n",
    "    # normalized.groupby('exp')[toplot].mean(numeric_only=False).dropna(axis=1).T,\n",
    "    normalized.groupby('exp')[toplot].median(numeric_only=False).dropna(axis=1).T,\n",
    "    # normalized[toplot].dropna(axis=1).clip(-10, 10),\n",
    "    # dat,\n",
    "    cmap='vlag',\n",
    "    center = 0,\n",
    "    annot=True,\n",
    "    # row_colors=row_colors,\n",
    ")\n",
    "\n",
    "# handles = [Patch(facecolor=lut[name]) for name in lut]\n",
    "# plt.legend(handles, lut, title='Treatment',\n",
    "#            bbox_to_anchor=(1, 1), bbox_transform=plt.gcf().transFigure, loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958f677-3a97-4694-9c68-3c6e9f70ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualitative heat map\n",
    "\n",
    "lut = dict(zip(normalized.exp.unique(), sns.color_palette()))\n",
    "row_colors = normalized.exp.map(lut)\n",
    "# dat = np.log2(normalized.groupby('exp')[toplot].median(numeric_only=False)).replace(-np.inf, np.nan).dropna(axis=1).T.copy()\n",
    "# cutoffs = [np.log2(1.25), np.log2(2), np.log2(4)]\n",
    "dat = normalized.groupby('exp')[toplot].median(numeric_only=False).dropna(axis=1).T.copy()\n",
    "cutoffs = [1, 2, 4]\n",
    "dat[np.abs(dat.to_numpy()) < cutoffs[0]] = 0\n",
    "for i in range(1, len(cutoffs)):\n",
    "    dat[(dat.to_numpy() > cutoffs[i-1]) & (dat.to_numpy() < cutoffs[i])] = i\n",
    "    dat[(dat.to_numpy() < -cutoffs[i-1]) & (dat.to_numpy() > -cutoffs[i])] = -i\n",
    "\n",
    "dat[dat.to_numpy() > cutoffs[i]] = i+1\n",
    "dat[dat.to_numpy() < -cutoffs[i]] = -i-1\n",
    "dat_map = ['0']\n",
    "dat_map += [f\"${'+'*(i+1)}$\" for i in range(len(cutoffs))]\n",
    "dat_map += [f\"${'-'*(i)}$\" for i in range(len(cutoffs), 0, -1)]\n",
    "\n",
    "sns.clustermap(\n",
    "    dat,\n",
    "    cmap='vlag',\n",
    "    center = 0,\n",
    "    annot=np.vectorize(lambda x: dat_map[x])(dat.astype(int)),\n",
    "    fmt=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4adf17-8c76-4369-9d07-b8796c9c71c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  plot the correlation metric for EU vs GC or FISH vs GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09e5a9-4908-461c-8cef-004a1bb413cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.groupby('exp').sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429821e5-bdd3-4547-858d-e98cb2843f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_plot_map = {\n",
    "    'CX': {\n",
    "        'x': 'time', 'hue': 'probe',\n",
    "    },\n",
    "    'FVP_nodfc': {\n",
    "        'x': 'time', 'hue': 'treatment',\n",
    "    },\n",
    "    'FVP_FISH': {\n",
    "        'x': 'time', 'hue': 'probe',\n",
    "    },\n",
    "    'Fib': {\n",
    "        'x': 'time', 'hue': 'treatment',\n",
    "    },\n",
    "    'RPL5': {\n",
    "        'x': 'time', 'hue': 'treatment',\n",
    "    },\n",
    "    'U3U8_EU': {\n",
    "        'x': 'time', 'hue': 'treatment',\n",
    "    },\n",
    "}\n",
    "for exp, params in exp_plot_map.items():\n",
    "    fig, ax = plt.subplots()\n",
    "    dat = full_data[full_data.exp == exp]\n",
    "    sns.lineplot(data=dat, y='Correlation_GC_Probe', **params, ax=ax)\n",
    "    ax.set_title(exp)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dat = full_data[full_data.exp == 'RPL5_FISH']\n",
    "sns.barplot(data=dat, y='Correlation_GC_Probe', x='probe', hue='treatment', ax=ax, hue_order=['SCR', 'RPL5KD'])\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dat = full_data[(full_data.exp == 'FVP_FISH')]\n",
    "sns.barplot(data=dat, y='Correlation_GC_Probe', x='probe', hue='time', ax=ax)\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30261af6-b073-4ab3-a88e-5de89475531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = full_data[full_data.exp.isin(('FVP_nodfc', 'Fib', 'RPL5', 'U3U8_EU'))].copy()\n",
    "dat['treated'] = 'control'\n",
    "dat.loc[~dat['treatment'].isin(('ctl', 'DMSO', 'SCR', 'ctlASO')), 'treated'] = 'treated'\n",
    "sns.lineplot(data=dat, y='Correlation_GC_Probe', x='time', hue='exp', style='treated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e76fa-f58f-4170-9b2c-7b415d590ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.groupby(['exp', 'treated', 'time'])['Count_FC'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0321b-2a55-46ce-9a84-23a5348b4386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## U3U8_EU, filter on dfc rim enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7204e8-b84e-45f7-bb41-e0bf2eb7c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U3U8_EU, filter on dfc rim enrichment\n",
    "dat = full_data[full_data.exp == 'U3U8_EU'].copy()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "sns.ecdfplot(x='fc_rim_enrichment', data=dat, hue='treatment', ax=ax[0])\n",
    "sns.ecdfplot(x='dfc_rim_enrichment', data=dat, hue='treatment', ax=ax[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "sns.kdeplot(x='fc_rim_enrichment', data=dat, hue='treatment', ax=ax[0])\n",
    "ax[0].axvline(0.9)\n",
    "sns.kdeplot(x='dfc_rim_enrichment', data=dat, hue='treatment', ax=ax[1])\n",
    "fig.suptitle('Pre Filter')\n",
    "dat_filt = dat[\n",
    "    ~((dat.treatment == 'U3ASO') & (dat.fc_rim_enrichment < 0.9)) &\n",
    "    ~((dat.treatment == 'U8ASO') & (dat.fc_rim_enrichment < 0.9))\n",
    "]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "sns.kdeplot(x='fc_rim_enrichment', data=dat_filt, hue='treatment', ax=ax[0])\n",
    "sns.kdeplot(x='dfc_rim_enrichment', data=dat_filt, hue='treatment', ax=ax[1])\n",
    "fig.suptitle('Post Filter')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "sns.lineplot(data=dat, y='Correlation_GC_Probe', x='time', hue='treatment', ax=ax[0])\n",
    "ax[0].set_title('Pre Filter')\n",
    "sns.lineplot(data=dat_filt, y='Correlation_GC_Probe', x='time', hue='treatment', ax=ax[1])\n",
    "ax[1].set_title('Post Filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f90b4-3966-4302-a17d-63484bff3976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ded29c15-2b87-4fc6-9e36-451c2cf2bf40",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c341de-5f3c-4a17-9308-5e8dc20ce8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized[\n",
    "    ((normalized.time == 0) | (normalized.time == 90)) &\n",
    "    normalized.treated &\n",
    "    (normalized.exp == '3 color')\n",
    "].groupby('treatment').Count_GC.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27b0eb-8150-4024-9c6c-c27d56f7706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = normalized[\n",
    "    ((normalized.time == 0) | (normalized.time == 90)) &\n",
    "    normalized.treated &\n",
    "    (normalized.exp == '3 color')\n",
    "].groupby('treatment').sample(frac=1).groupby('treatment').head(200)\n",
    "features = sub_data[toplot].copy()\n",
    "features = features.fillna(0)\n",
    "labels = sub_data['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645fce7-1096-4090-a8a3-bc58d79d5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f9c64-7059-40fd-b237-8e7726559b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_features)\n",
    "lbls = test_labels.unique()\n",
    "mat = sklearn.metrics.confusion_matrix(test_labels, predictions, labels=lbls, normalize='true')\n",
    "print(np.diag(mat).sum() / mat.sum())\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(mat, display_labels=lbls)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa6e76-2caa-4995-8639-6583eb04bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}\n",
    "for depth in range(2, 20):\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=0)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    predictions = clf.predict(test_features)\n",
    "    mat = sklearn.metrics.confusion_matrix(test_labels, predictions, labels=lbls, normalize='true')\n",
    "    acc[depth] = np.diag(mat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48712b-7bd4-411a-92b9-bf62033cfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=acc.keys(), y=acc.values())\n",
    "ax.set_xlabel('Max Tree Depth')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.axvline(7)\n",
    "ax.axhline(acc[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b237095-309b-4f64-9fde-055283a54da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "lbls = test_labels.unique()\n",
    "mat = sklearn.metrics.confusion_matrix(test_labels, predictions, labels=lbls, normalize='true')\n",
    "print(np.diag(mat).sum() / mat.sum())\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(mat, display_labels=lbls)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8307c-22cb-4736-89cc-4a92f806fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(features.columns, clf.feature_importances_)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {:0.3f}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "ax = sns.barplot(x=[x[0] for x in feature_importances], y=[x[1] for x in feature_importances])\n",
    "plt.xticks(rotation=50, ha='right')\n",
    "ax.set_ylabel('Gini Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab54a8-c551-4db4-b35e-804d0e4a50e8",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bd57f-1a73-49ae-9f2e-86c0cd7fc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "pcs = pd.concat(\n",
    "    (pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'], index=features.index),\n",
    "     labels), axis=1,\n",
    ")\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='treatment', data=pcs.groupby('treatment').mean(), ax=ax[0])\n",
    "ax[1].set_xlim(-1, 1)\n",
    "ax[1].set_ylim(-1, 1)\n",
    "for comp, lbl in zip(pca.components_.T, features.columns):\n",
    "    ax[1].arrow(0, 0, comp[0], comp[1], color='k', alpha=0.5)\n",
    "    ax[1].text(comp[0]* 1.15, comp[1] * 1.15, lbl, color='k', ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c060b-91ca-4c28-8e6a-09e5c85efa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(pca.components_, axis=0)\n",
    "idx = np.argsort(-norms)\n",
    "sns.barplot(x=features.columns[idx], y=norms[idx])\n",
    "plt.xticks(rotation=50, ha='right') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cd474-1d8a-401e-880f-ea80cbd5f396",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# morph plate 7/3\n",
    "\n",
    "3 color:\n",
    "- D2-D5  FVP 0min, 30min, 60min, 90min (U3 FISH)\n",
    "- D6-D9 FVP 0min, 30min, 60min, 90min (U8 FISH)\n",
    "- F2-F5  CX 0min, 30min, 60min, 90min (U3 FISH)\n",
    "- F6-F9 CX 0min, 30min, 60min, 90min (U8 FISH)\n",
    "- E2-E9: U3ASO (U3FISH), U3SCR(U3FISH), U8ASO(U8FISH), U8SCR(U8FISH); FibsiRNA(U3FISH); Fibctl(U3FISH); RPL5shRNA(U8FISH); RPL5ctl (U8FISH)\n",
    "\n",
    "no color:\n",
    "- C2-C5  FVP 0min, 30min, 60min, 90min (U3 FISH)\n",
    "- C6-C9 FVP 0min, 30min, 60min, 90min (U8 FISH)\n",
    "- E2-E5  CX 0min, 30min, 60min, 90min (U3 FISH)\n",
    "- E6-E9 CX 0min, 30min, 60min, 90min (U8 FISH)\n",
    "  \n",
    "in the morph_nocolor subfolder:\n",
    "- C2-C9: C2- U3ASO (U3FISH), C3-U3SCR(U3FISH), C4-U8ASO(U8FISH), C5-U8SCR(U8FISH); C6-FibsiRNA(U3FISH); C7-Fibctl(U3FISH); C8-RPL5shRNA(U8FISH); C9-RPL5ctl (U8FISH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c0d07-9c1e-4ca4-8647-bab9024c3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('morphology/morph_3color/outputs', r'.*/(?P<subdir>[^/]+)/Well(?P<well>[A-G]\\d+)_.*nd2', bins=4, dfc_intens=True).assign(exp='3 color')\n",
    "well_map = {\n",
    "    'D02': ('FVP',  0, 'U3Fish'),\n",
    "    'D03': ('FVP', 30, 'U3Fish'),\n",
    "    'D04': ('FVP', 60, 'U3Fish'),\n",
    "    'D05': ('FVP', 90, 'U3Fish'),\n",
    "    'D06': ('FVP',  0, 'U8Fish'),\n",
    "    'D07': ('FVP', 30, 'U8Fish'),\n",
    "    'D08': ('FVP', 60, 'U8Fish'),\n",
    "    'D09': ('FVP', 90, 'U8Fish'),\n",
    "    \n",
    "    'F02': ('CX',  0, 'U3Fish'),\n",
    "    'F03': ('CX', 30, 'U3Fish'),\n",
    "    'F04': ('CX', 60, 'U3Fish'),\n",
    "    'F05': ('CX', 90, 'U3Fish'),\n",
    "    'F06': ('CX',  0, 'U8Fish'),\n",
    "    'F07': ('CX', 30, 'U8Fish'),\n",
    "    'F08': ('CX', 60, 'U8Fish'),\n",
    "    'F09': ('CX', 90, 'U8Fish'),\n",
    "    \n",
    "    'E02': ('U3ASO', 0, 'U3Fish'),\n",
    "    'E03': ('U3SCR', 0, 'U3Fish'),\n",
    "    'E04': ('U8ASO', 0, 'U8Fish'),\n",
    "    'E05': ('U8SCR', 0, 'U8Fish'),\n",
    "    'E06': ('FibsiRNA',  0, 'U3Fish'),\n",
    "    'E07': ('Fibctl', 0, 'U3Fish'),\n",
    "    'E08': ('RPL5shRNA', 0, 'U8Fish'),\n",
    "    'E09': ('RPL5ctl', 0, 'U8Fish'),\n",
    "}\n",
    "color_data = data.join(\n",
    "    pd.DataFrame([v for v in data.well.map(well_map)], columns=['treatment', 'time', 'probe']),\n",
    ")\n",
    "color_data = color_data[color_data.well != 'E09']  # bad sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e031c-1ab7-46dd-a202-197f35b83f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('morphology_altchan/morph_nocolor/outputs', r'.*/(?P<subdir>[^/]+)/Well(?P<well>[A-G]\\d+)_.*nd2', bins=4, dfc_intens=True).assign(exp='no color')\n",
    "\n",
    "well_map = {\n",
    "    'C02': ('FVP',  0, 'U3Fish'),\n",
    "    'C03': ('FVP', 30, 'U3Fish'),\n",
    "    'C04': ('FVP', 60, 'U3Fish'),\n",
    "    'C05': ('FVP', 90, 'U3Fish'),\n",
    "    'C06': ('FVP',  0, 'U8Fish'),\n",
    "    'C07': ('FVP', 30, 'U8Fish'),\n",
    "    'C08': ('FVP', 60, 'U8Fish'),\n",
    "    'C09': ('FVP', 90, 'U8Fish'),\n",
    "    \n",
    "    'E02': ('CX',  0, 'U3Fish'),\n",
    "    'E03': ('CX', 30, 'U3Fish'),\n",
    "    'E04': ('CX', 60, 'U3Fish'),\n",
    "    'E05': ('CX', 90, 'U3Fish'),\n",
    "    'E06': ('CX',  0, 'U8Fish'),\n",
    "    'E07': ('CX', 30, 'U8Fish'),\n",
    "    'E08': ('CX', 60, 'U8Fish'),\n",
    "    'E09': ('CX', 90, 'U8Fish'),\n",
    "}\n",
    "\n",
    "data = data.join(\n",
    "    pd.DataFrame([v for v in data.well.map(well_map)], columns=['treatment', 'time', 'probe']),\n",
    ")\n",
    "\n",
    "# morph nocolor subdir\n",
    "nocolor = data[data.subdir == 'morph_nocolor']\n",
    "well_map = {\n",
    "    'C02': ('U3ASO', 0, 'U3Fish'),\n",
    "    'C03': ('U3SCR', 0, 'U3Fish'),\n",
    "    'C04': ('U8ASO', 0, 'U8Fish'),\n",
    "    'C05': ('U8SCR', 0, 'U8Fish'),\n",
    "    'C06': ('FibsiRNA',  0, 'U3Fish'),\n",
    "    'C07': ('Fibctl', 0, 'U3Fish'),\n",
    "    'C08': ('RPL5shRNA', 0, 'U8Fish'),\n",
    "    'C09': ('RPL5ctl', 0, 'U8Fish'),\n",
    "}\n",
    "    \n",
    "nocolor = pd.DataFrame([v for v in nocolor.well.map(well_map)], columns=['treatment', 'time', 'probe'])\n",
    "data.loc[\n",
    "    data.subdir == 'morph_nocolor',\n",
    "    ['treatment', 'time', 'probe'],\n",
    "] = nocolor.to_numpy()\n",
    "\n",
    "# add in newer U3/U8 data\n",
    "no_color_redo = read_data('morphology_altchan/morph_nocolor_redo/outputs', r'.*/(?P<subdir>[^/]+)/(?P<well>[A-G]\\d+)_(?P<treatment>[^0]+).*nd2',\n",
    "                          bins=2, dfc_intens=True).assign(exp='no color redo', time=0)\n",
    "\n",
    "data = pd.concat([data, color_data, no_color_redo], ignore_index=True)\n",
    "\n",
    "# split out control vs treatment and treatment name to simplify facets\n",
    "data['treated'] = data.time != 0  # initialize\n",
    "data.loc[\n",
    "    data.treatment.isin(['FibsiRNA', 'U3ASO', 'U8ASO', 'RPL5shRNA']),\n",
    "    'treated'] = True\n",
    "data['treatment'] = data.treatment.str.replace(r'ctl|siRNA|shRNA|ASO|SCR$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5f1a0-c225-4f6e-9249-ce1ce4172019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove U3/U8 no color data, replace with repeat\n",
    "data = data[~((data.exp == 'no color') & (data.treatment.isin(('U3', 'U8'))))]\n",
    "data.loc[data.exp == 'no color redo', 'exp'] = 'no color'\n",
    "data.groupby(['exp', 'treatment', 'treated']).Count_GC.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67574feb-e3a3-4bd5-a16e-78a93b4ff3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['exp', 'treatment', 'treated']).Count_GC.count()\n",
    "data.to_csv('morph_plate_U3U8_redo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae3fa5-7d98-4e2c-aeb6-dcd350375c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312f61a-0fdf-4651-968a-6349531a9056",
   "metadata": {},
   "source": [
    "### KD efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f0801-0b71-4f67-9ba2-9eece5f3c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = data[data.treatment.isin(('U3', 'U8'))].copy()\n",
    "\n",
    "sns.displot(\n",
    "    data=to_plot,\n",
    "    x='mean_mean_Probe_intens',\n",
    "    col='exp',\n",
    "    row='treatment',\n",
    "    hue='treated',\n",
    "    kind='ecdf',\n",
    "    facet_kws=dict(sharex='row'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f3e80-29dc-455c-90cd-0b517673695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = data[data.treatment.isin(('Fib',))].copy()\n",
    "\n",
    "sns.displot(\n",
    "    data=to_plot,\n",
    "    x='mean_mean_DFC_intens',\n",
    "    col='exp',\n",
    "    row='treatment',\n",
    "    hue='treated',\n",
    "    kind='ecdf',\n",
    "    facet_kws=dict(sharex='row'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbe6be-9167-425a-980a-cd35e2def2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('morph_plate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb0a20-1f03-4879-922b-c3413e6042e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96940966-8de1-4695-b0d9-777fdef0d560",
   "metadata": {},
   "source": [
    "- Maybe the heat map for the key parameters across perturbations\n",
    "- Also to see if all controls are clustered together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea46da-b576-4d5c-956d-69117c08fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = [c for c in data.columns[6:] \n",
    "              # if (c.startswith('Count') or\n",
    "              # c.startswith('Correlation') or\n",
    "              # c.startswith('mean_mean_GC') or\n",
    "              # c in ('GC_area', 'mean_GC_circularity',) or\n",
    "              # c.endswith('enrichment')) and\n",
    "             if 'Probe' not in c \n",
    "          and c not in ( 'exp',\n",
    " 'treatment',\n",
    " 'time',\n",
    " 'probe',\n",
    " 'treated',\n",
    " 'center_x',\n",
    " 'center_y',\n",
    "                       )\n",
    "          and not c.startswith('total')\n",
    "          and 'DFC_intens' not in c\n",
    "         ]\n",
    "toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0cb262-051c-4d06-9c19-9db1f68de0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data[\n",
    "    ((data.treatment == 'U3') & ((data.mean_mean_Probe_intens < 0.002) | ~data.treated)) |\n",
    "    ((data.treatment == 'U8') & (data.exp == '3 color') & ((data.mean_mean_Probe_intens < 0.00157) | ~data.treated)) |\n",
    "    ((data.treatment == 'U8') & (data.exp == 'no color') & ((data.mean_mean_Probe_intens < 0.0018) | ~data.treated)) |\n",
    "    ((data.treatment == 'Fib') & ((data.mean_mean_DFC_intens < 0.003) | ~data.treated)) |\n",
    "    ~data.treatment.isin(('U3', 'U8', 'Fib'))\n",
    "].copy()\n",
    "\n",
    "df = dat[dat.exp == 'no color'].copy()\n",
    "print(df.groupby(['treatment', 'treated']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "order = df.treatment.unique()\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df[df.treated == False], x=col, hue='treatment', linestyle='--', ax=ax, hue_order=order)\n",
    "    # sns.ecdfplot(data=df[df.treated == False], x=col, c='k', linestyle='--', ax=ax, hue_order=order)\n",
    "    # sns.ecdfplot(data=df[df.treated == True], x=col, hue='treatment', linestyle='-', ax=ax, hue_order=order)\n",
    "\n",
    "plt.savefig('noColorMorphRedo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78abb1-a75f-46cc-92b4-dc8fdfce2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data[\n",
    "    ((data.treatment == 'U3') & ((data.mean_mean_Probe_intens < 0.002) | ~data.treated)) |\n",
    "    ((data.treatment == 'U8') & (data.exp == '3 color') & ((data.mean_mean_Probe_intens < 0.00157) | ~data.treated)) |\n",
    "    ((data.treatment == 'U8') & (data.exp == 'no color') & ((data.mean_mean_Probe_intens < 0.0018) | ~data.treated)) |\n",
    "    ((data.treatment == 'Fib') & ((data.mean_mean_DFC_intens < 0.003) | ~data.treated)) |\n",
    "    ~data.treatment.isin(('U3', 'U8', 'Fib', 'CX'))\n",
    "].copy()\n",
    "\n",
    "# normalize within each treatment\n",
    "# normalized = dat.groupby(['treatment', 'exp'], group_keys=False)[toplot + ['treated']].apply(\n",
    "#     lambda x: (x - x[x.treated == False].mean()) / x[x.treated == False].std()).drop(columns='treated')\n",
    "# normalize against all \n",
    "normalized = dat.groupby(['exp'], group_keys=False)[toplot + ['treated']].apply(\n",
    "    lambda x: (x - x[x.treated == False].mean()) / x[x.treated == False].std()).drop(columns='treated')\n",
    "normalized = normalized.join(dat[['treatment', 'time', 'exp', 'treated']])\n",
    "normalized.groupby(['treatment', 'time', 'treated', 'exp']).Count_GC.count()\n",
    "# normalized.to_csv('morph_plate_normalized_redo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0fb55-44c1-4e32-b234-549adcbfc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = normalized[normalized.treatment == 'CX'].copy()\n",
    "df = data[data.treatment == 'FVP'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "print(df.groupby(['exp', 'treatment', 'time']).Count_GC.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for exp, line in zip(('no color', '3 color'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.exp==exp], x=col, hue='time', ax = ax, linestyle=line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8baa46-6c0f-4583-8d0f-500443c13d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = normalized[\n",
    "    ((normalized.time == 0) | (normalized.time == 90)) &\n",
    "    normalized.treated &\n",
    "    (normalized.exp == '3 color')\n",
    "].copy()\n",
    "print(dat.groupby(['treatment', 'time', 'treated', 'exp']).Count_GC.count())\n",
    "dat = dat.groupby('treatment')[toplot].agg({\n",
    "     'Count_GC': 'mean',\n",
    "     'Count_FC': 'mean',\n",
    "     'Count_Nucleoplasmic_FC': 'mean',\n",
    "     'mean_GC_circularity': 'median',\n",
    "     'GC_area': 'median',\n",
    "     'mean_mean_GC_intens': 'median',\n",
    "     'fc_rim_enrichment': 'median',\n",
    "     'dfc_rim_enrichment': 'median',\n",
    "     'Correlation_DFC_FC': 'median',\n",
    "     'Correlation_DFC_GC': 'median',\n",
    "     'Correlation_FC_GC': 'median',\n",
    "     'Overlap_DFC_FC': 'median',\n",
    "     'Overlap_DFC_GC': 'median',\n",
    "     'Overlap_FC_GC': 'median',\n",
    "     'mean_GC_eccentricity': 'median',\n",
    "     'FC_area': 'median',\n",
    "     'FC_density': 'median',\n",
    "     'combined_area': 'median'\n",
    "}).T\n",
    "# dat = dat.groupby('treatment')[toplot].mean().T\n",
    "sns.clustermap(\n",
    "    dat,\n",
    "    cmap='vlag',\n",
    "    center = 0,\n",
    "    annot=True,\n",
    ")\n",
    "dat.to_csv('3_color_heatmap_redo_noCX.csv')\n",
    "plt.savefig('3_color_heatmap_redo_noCX.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965a591-3adf-4c6b-b32f-267be137404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = normalized[\n",
    "    ((normalized.time == 0) | (normalized.time == 90)) &\n",
    "    normalized.treated &\n",
    "    (normalized.exp == 'no color')\n",
    "].copy()\n",
    "features = sub_data[toplot].copy()\n",
    "# features = features.fillna(0)\n",
    "labels = sub_data['treatment']\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "pcs = pd.concat(\n",
    "    (pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'], index=features.index),\n",
    "     labels), axis=1,\n",
    ")\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='treatment', data=pcs.groupby('treatment').mean(), ax=ax[0])\n",
    "ax[1].set_xlim(-1, 1)\n",
    "ax[1].set_ylim(-1, 1)\n",
    "for comp, lbl in zip(pca.components_.T, features.columns):\n",
    "    ax[1].arrow(0, 0, comp[0], comp[1], color='k', alpha=0.5)\n",
    "    ax[1].text(comp[0]* 1.15, comp[1] * 1.15, lbl, color='k', ha='center', va='center')\n",
    "\n",
    "# plt.savefig('no_color_pca_redo.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493ca88-410e-4f71-906b-7cae6c965986",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CP RDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8d275-a90d-4db5-bfde-2a082a615f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rdf(result, directory, common):\n",
    "    cols = open(directory / 'InitialGC.csv', 'r').readline().split(',')\n",
    "    nucl = pd.read_csv(\n",
    "        directory / 'InitialGC.csv',\n",
    "        usecols=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC'] + [c.strip() for c in cols if c.startswith('RDF_')],\n",
    "        )\n",
    "    # intensity\n",
    "    nucl = nucl.melt(id_vars=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC'])\n",
    "    rdf = nucl[nucl.variable.str.startswith('RDF_Intensity')].reset_index(drop=True)\n",
    "    extract = rdf.variable.str.extract(r'RDF_Intensity_C(\\d)_R([-0-9]+)')\n",
    "    rdf = rdf.assign(\n",
    "        channel=extract[0].astype(int),\n",
    "        radius=extract[1].astype(int),\n",
    "    ).rename(columns={'value': 'intensity'}).drop(columns='variable')\n",
    "\n",
    "    counts = nucl[nucl.variable.str.startswith('RDF_Count')].reset_index(drop=True)\n",
    "    extract = counts.variable.str.extract(r'RDF_Counts_R([-0-9]+)')\n",
    "    counts = counts.assign(\n",
    "        radius=extract[0].astype(int)\n",
    "    ).rename(columns={'value': 'counts'}).drop(columns='variable')\n",
    "\n",
    "    rdf = rdf.merge(counts, on=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC', 'radius'])\n",
    "\n",
    "    return result, rdf\n",
    "\n",
    "def read_data(directory, regex=None, dfc=True, bins=4, dfc_intens=False):\n",
    "    directory = Path(directory)\n",
    "    # image and object number are uniuqe identifiers.  Area is used a lot and the parent_mergedGC should corresopnd to a single cell\n",
    "    common = ['ImageNumber', 'ObjectNumber', 'AreaShape_Area', 'Parent_DilatedGC']\n",
    "\n",
    "    result = build_initial_data(directory, common, regex)\n",
    "    \n",
    "    result = add_initial_gc(result, directory, common, dfc_intens)\n",
    "    \n",
    "    result = add_initial_fc(result, directory, common)\n",
    "    \n",
    "    result = add_rim(result, directory, common, dfc, bins, total=20)\n",
    "    \n",
    "    result = add_correlation(result, directory, common)\n",
    "\n",
    "    result, rdf = add_rdf(result, directory, common)\n",
    "    \n",
    "    return result.drop(columns='Parent_DilatedGC'), rdf\n",
    "\n",
    "data, rdf = read_data('morphology_rdf/RPL5/outputs/',  r'/[A-G]\\d+_(?P<treatment>SCR|RPL5KD)_15p(?P<time>\\d+)c.*nd2')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c070c-abec-44ef-a40a-823f79b44392",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59aa0a2-a248-4585-8d5b-20f35c40609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to average GCs from each parent\n",
    "rdf_avg = []\n",
    "groups = ['ImageNumber', 'Parent_DilatedGC', 'channel', 'radius']\n",
    "for name, dat in rdf.groupby(groups):\n",
    "    rdf_avg.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        counts=dat['counts'].sum(),\n",
    "    ))\n",
    "rdf_avg = pd.DataFrame(rdf_avg)\n",
    "rdf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e37218-98af-4d1a-8653-d0e6b084f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rdf_avg = pd.DataFrame(rdf_avg)\n",
    "rdf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ce410-3831-4091-9607-a38be125d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell information\n",
    "merged = rdf_avg.merge(data[['ImageNumber', 'CellNumber', 'time', 'treatment']], \n",
    "                   left_on=['ImageNumber', 'Parent_DilatedGC'], \n",
    "                   right_on=['ImageNumber', 'CellNumber'])\n",
    "# average raw values based on target and ssu\n",
    "groups = ['time', 'treatment', 'channel', 'radius']\n",
    "channels = ['', 'EU', 'DFC', 'FC', 'GC']\n",
    "rdf_data = []\n",
    "for name, dat in merged.groupby(groups):\n",
    "    rdf_data.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        channel=channels[name[2]]\n",
    "    ))\n",
    "rdf_data = pd.DataFrame(rdf_data)  \n",
    "rdf_data['time'] = rdf_data.time.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83122a70-41c0-477f-aca6-692d58e080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=rdf_data, x='radius', y='intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e547219-d395-44ae-ad5d-380fd467e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = rdf_data.copy()\n",
    "normalized['normalized_intensity'] = normalized.groupby(['channel', 'treatment', 'time']).intensity.transform(lambda x: (x - x.min()) / (x.max() - x.min()), )\n",
    "sns.relplot(data=normalized, x='radius', y='normalized_intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ca50d-8e97-411f-9f51-ff7c144b735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=normalized, x='radius', y='normalized_intensity', col='time', col_wrap=3,\n",
    "            kind='line', style='treatment', hue='channel', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82e809-6db1-4d7d-81f1-ec0d13001038",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized.to_csv('rpl5_rdf_cp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9f208-7598-4fad-af16-e80d08a6a080",
   "metadata": {},
   "source": [
    "# More Fish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75292742-ca03-4b91-9d3f-cd3f2cf40216",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('morphology/240824_FISH/outputs', r'/.*_10A_(?P<probe>[^_0]+)(?:\\d{3}\\d?)?.nd2', bins=4)\n",
    "# data.loc[data.isna().any(axis=1), 'Metadata_FileLocation'].unique()\n",
    "data.probe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353f381-6b52-4ada-84d1-307340ff2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = [c for c in data.columns if c.startswith('Correlation')]\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "order = data.probe.unique()\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    # sns.ecdfplot(data=data[data.Correlation_DFC_FC > 0.2], x=col, hue='probe', ax=ax, hue_order=order, legend=col.endswith('GC_Probe'))\n",
    "    sns.ecdfplot(data=data, x=col, hue='probe', ax=ax, hue_order=order, legend=col.endswith('GC_Probe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2f43f-be20-4b03-8e21-c2f995d04109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('240824_FISH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98e7bf-0301-4d5c-8115-34f5e06d0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['filename'] = data.Metadata_FileLocation.str.extract(r'.*/(.+).nd2')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b83e60-b904-4348-83a0-a24c334a5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodal_probes = data[data.Correlation_DFC_FC < 0.2].groupby('probe').Correlation_DFC_FC.count().sort_values(ascending=False).head(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0110b43-ca9d-4598-82bd-c9a1ff404036",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Correlation_DFC_FC < 0.2].groupby('filename').Correlation_DFC_FC.count().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bc987-9793-4914-9d21-becbad4dc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data[data.probe.isin(bimodal_probes)], col='probe', col_wrap=4, x='Correlation_DFC_FC', kind='ecdf', hue='filename', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5408395-74e7-49bd-b0e4-c61c309bae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.probe.isin(bimodal_probes)].groupby('filename').Correlation_DFC_FC.mean().sort_values(ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c3ada-c674-408d-a86d-ea3db19c2b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
