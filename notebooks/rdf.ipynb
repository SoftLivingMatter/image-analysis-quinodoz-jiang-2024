{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a28cd-0c97-4249-be9c-2c81d26eec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import utils\n",
    "import functools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66618d-99d1-47f6-912f-35fa5d4e8fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defined for each pipeline to simplify data parsing\n",
    "def read_data(directory, regex=None, dfc=True, bins=4, debug_regex=False):\n",
    "    directory = Path(directory)\n",
    "    # some variables reused below\n",
    "    extra_columns = ['ImageNumber', 'Parent_DilatedGC']\n",
    "    \n",
    "    extras = {\n",
    "        'extra_columns': extra_columns,\n",
    "        'reduce': True,\n",
    "        'merge_fcn': functools.partial(utils.merge_reduced, merge_on=extra_columns)\n",
    "    }\n",
    "    \n",
    "    extras_left = {\n",
    "        'extra_columns': extra_columns,\n",
    "        'reduce': True,\n",
    "        'merge_fcn': functools.partial(utils.merge_reduced, merge_on=extra_columns, how='left')\n",
    "    }\n",
    "\n",
    "    # Parse information from filename using the provided regex\n",
    "    result, _ = utils.analyze(directory / 'Image.csv', \n",
    "                              parsers=[\n",
    "                                  utils.ImageParser(regex, debug_regex=debug_regex),                              \n",
    "                              ])\n",
    "    # Combine with DilatedGC for using to merge with other measures\n",
    "    result, _ = utils.analyze(directory / 'DilatedGC.csv',\n",
    "                              previous_result=result,\n",
    "                              parsers=[utils.BlankParser(['ObjectNumber'])],\n",
    "                              extra_columns=['ImageNumber', ],\n",
    "                              merge_fcn=functools.partial(utils.merge_result, merge_on=['ImageNumber'], how='left'),\n",
    "                             )\n",
    "    result = result.rename(columns={'ObjectNumber': 'Parent_DilatedGC'})\n",
    "\n",
    "    # Measure features from GC objects\n",
    "    result, extra = utils.analyze(directory / 'InitialGC.csv',\n",
    "                              previous_result=result,\n",
    "                              parsers=[\n",
    "                                  utils.CountingParser(),\n",
    "                                  utils.ShapeParser(),\n",
    "                                  utils.RDFParser(id_vars=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC']),\n",
    "                              ],\n",
    "                              region='GC',\n",
    "                              **extras\n",
    "                             )\n",
    "    \n",
    "    # Measure features from FC objects\n",
    "    result, _ = utils.analyze(directory / 'InitialFC.csv',\n",
    "                              previous_result=result,\n",
    "                              parsers=[\n",
    "                                  utils.CountingParser(),\n",
    "                                  utils.ShapeParser(),\n",
    "                              ],\n",
    "                              region='FC',\n",
    "                              **extras_left\n",
    "                             )\n",
    "    \n",
    "    return result, extra\n",
    "\n",
    "# multiple dataframes can be combined with unique experiments and subsets of overlapping variables (e.g. time or treatment)\n",
    "full_data, extra_data = read_data('/scratch/gpfs/tcomi/cp_paper_redo/rdf/testing/outputs', \n",
    "                      r'/[A-G]\\d+_(?P<treatment>SCR|RPL5KD)_15p(?P<time>\\d+)c.*nd2', bins=4)\n",
    "rdf, = extra_data\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59aa0a2-a248-4585-8d5b-20f35c40609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to average GCs from each parent\n",
    "rdf_avg = []\n",
    "groups = ['ImageNumber', 'Parent_DilatedGC', 'channel', 'radius']\n",
    "for name, dat in rdf.groupby(groups):\n",
    "    rdf_avg.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        counts=dat['counts'].sum(),\n",
    "    ))\n",
    "rdf_avg = pd.DataFrame(rdf_avg)\n",
    "rdf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ce410-3831-4091-9607-a38be125d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell information\n",
    "merged = rdf_avg.merge(full_data[['ImageNumber', 'Parent_DilatedGC', 'time', 'treatment']], \n",
    "                   on=['ImageNumber', 'Parent_DilatedGC'])\n",
    "# average raw values based on target and ssu\n",
    "groups = ['time', 'treatment', 'channel', 'radius']\n",
    "channels = ['', 'EU', 'DFC', 'FC', 'GC']\n",
    "rdf_data = []\n",
    "for name, dat in merged.groupby(groups):\n",
    "    rdf_data.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        channel=channels[name[2]]\n",
    "    ))\n",
    "rdf_data = pd.DataFrame(rdf_data)  \n",
    "rdf_data['time'] = rdf_data.time.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83122a70-41c0-477f-aca6-692d58e080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=rdf_data, x='radius', y='intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e547219-d395-44ae-ad5d-380fd467e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = rdf_data.copy()\n",
    "normalized['normalized_intensity'] = normalized.groupby(['channel', 'treatment', 'time']).intensity.transform(lambda x: (x - x.min()) / (x.max() - x.min()), )\n",
    "sns.relplot(data=normalized, x='radius', y='normalized_intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ca50d-8e97-411f-9f51-ff7c144b735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=normalized, x='radius', y='normalized_intensity', col='time', col_wrap=3,\n",
    "            kind='line', style='treatment', hue='channel', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc270e-e50b-44e3-8771-4e3e2edbeb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
