{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a28cd-0c97-4249-be9c-2c81d26eec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import utils\n",
    "import functools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66618d-99d1-47f6-912f-35fa5d4e8fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defined for each pipeline to simplify data parsing\n",
    "def read_data(directory, regex=None, dfc=True, bins=4, debug_regex=False):\n",
    "    directory = Path(directory)\n",
    "    # some variables reused below\n",
    "    extra_columns = ['ImageNumber', 'Parent_DilatedGC']\n",
    "    \n",
    "    extras = {\n",
    "        'extra_columns': extra_columns,\n",
    "        'reduce': True,\n",
    "        'merge_fcn': functools.partial(utils.merge_reduced, merge_on=extra_columns)\n",
    "    }\n",
    "    \n",
    "    extras_left = {\n",
    "        'extra_columns': extra_columns,\n",
    "        'reduce': True,\n",
    "        'merge_fcn': functools.partial(utils.merge_reduced, merge_on=extra_columns, how='left')\n",
    "    }\n",
    "\n",
    "    # Parse information from filename using the provided regex\n",
    "    result, _ = utils.analyze(directory / 'Image.csv', \n",
    "                              parsers=[\n",
    "                                  utils.ImageParser(regex, debug_regex=debug_regex),                              \n",
    "                              ])\n",
    "    # Combine with DilatedGC for using to merge with other measures\n",
    "    result, _ = utils.analyze(directory / 'DilatedGC.csv',\n",
    "                              previous_result=result,\n",
    "                              parsers=[utils.BlankParser(['ObjectNumber'])],\n",
    "                              extra_columns=['ImageNumber', ],\n",
    "                              merge_fcn=functools.partial(utils.merge_result, merge_on=['ImageNumber'], how='left'),\n",
    "                             )\n",
    "    result = result.rename(columns={'ObjectNumber': 'Parent_DilatedGC'})\n",
    "\n",
    "    # Measure features from GC objects\n",
    "    result, extra = utils.analyze(directory / 'InitialGC.csv',\n",
    "                              previous_result=result,\n",
    "                              parsers=[\n",
    "                                  utils.CountingParser(),\n",
    "                                  utils.ShapeParser(),\n",
    "                                  utils.RDFParser(id_vars=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC']),\n",
    "                              ],\n",
    "                              region='GC',\n",
    "                              **extras\n",
    "                             )\n",
    "    \n",
    "    # Measure features from FC objects\n",
    "    result, _ = utils.analyze(directory / 'InitialFC.csv',\n",
    "                              previous_result=result,\n",
    "                              parsers=[\n",
    "                                  utils.CountingParser(),\n",
    "                                  utils.ShapeParser(),\n",
    "                              ],\n",
    "                              region='FC',\n",
    "                              **extras_left\n",
    "                             )\n",
    "    \n",
    "    return result, extra\n",
    "\n",
    "# multiple dataframes can be combined with unique experiments and subsets of overlapping variables (e.g. time or treatment)\n",
    "full_data, extra_data = read_data('/scratch/gpfs/tcomi/cp_paper_redo/rdf/testing/outputs', \n",
    "                      r'/[A-G]\\d+_(?P<treatment>SCR|RPL5KD)_15p(?P<time>\\d+)c.*nd2', bins=4)\n",
    "rdf, = extra_data\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59aa0a2-a248-4585-8d5b-20f35c40609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to average GCs from each parent\n",
    "rdf_avg = []\n",
    "groups = ['ImageNumber', 'Parent_DilatedGC', 'channel', 'radius']\n",
    "for name, dat in rdf.groupby(groups):\n",
    "    rdf_avg.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        counts=dat['counts'].sum(),\n",
    "    ))\n",
    "rdf_avg = pd.DataFrame(rdf_avg)\n",
    "rdf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ce410-3831-4091-9607-a38be125d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell information\n",
    "merged = rdf_avg.merge(full_data[['ImageNumber', 'Parent_DilatedGC', 'time', 'treatment']], \n",
    "                   on=['ImageNumber', 'Parent_DilatedGC'])\n",
    "# average raw values based on target and ssu, estimate sem from total variance\n",
    "groups = ['time', 'treatment', 'channel']\n",
    "channels = ['', 'EU', 'DFC', 'FC', 'GC']\n",
    "rdf_data = []\n",
    "\n",
    "for name, dat in merged.groupby(groups):\n",
    "    pivoted = dat.pivot_table(columns='radius', values=['intensity', 'counts'], index=['ImageNumber', 'Parent_DilatedGC'])\n",
    "    average_intens = ((pivoted['intensity'] * pivoted['counts']).fillna(0).sum()) / pivoted['counts'].sum()\n",
    "    mn, mx = pivoted['intensity'].min(), pivoted['intensity'].max()\n",
    "    normed = (pivoted['intensity'] - mn) / (mx - mn)\n",
    "    \n",
    "    sem = np.sqrt((((normed - normed.mean())**2) * pivoted['counts']).sum() / pivoted['counts'].sum()) / np.sqrt(len(normed))\n",
    "    mn, mx = average_intens.min(), average_intens.max()\n",
    "    norm_intens = (average_intens - mn) / (mx - mn)\n",
    "    for radius, vals in pd.concat([norm_intens, average_intens, sem], axis=1).iterrows():\n",
    "        rdf_data.append(dict(\n",
    "            zip(groups, name),\n",
    "            norm_intensity=vals[0],\n",
    "            intensity=vals[1],\n",
    "            sem=vals[2],\n",
    "            channel=channels[name[2]],\n",
    "            radius=radius,\n",
    "        ))\n",
    "rdf_data = pd.DataFrame(rdf_data)  \n",
    "rdf_data['time'] = rdf_data.time.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83122a70-41c0-477f-aca6-692d58e080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=rdf_data, x='radius', y='intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e547219-d395-44ae-ad5d-380fd467e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=rdf_data, x='radius', y='norm_intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ca50d-8e97-411f-9f51-ff7c144b735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['EU', 'DFC', 'FC', 'GC']\n",
    "g = sns.relplot(data=rdf_data, x='radius', y='norm_intensity', col='time', col_wrap=3,\n",
    "            kind='line', style='treatment', hue='channel', facet_kws=dict(sharex=True, sharey=False), hue_order=channels)\n",
    "\n",
    "for time, ax in g.axes_dict.items():\n",
    "    for channel in channels:\n",
    "        sub_dat = rdf_data[(rdf_data.channel==channel) & (rdf_data.time == time)]\n",
    "        ax.fill_between(sub_dat.radius, sub_dat.norm_intensity - sub_dat['sem'], sub_dat.norm_intensity + sub_dat['sem'], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d21f1-caec-4a0f-8906-4710169adb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_data.channel.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7a4ed-97cc-477a-a194-b4010a9acec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peak position over time\n",
    "overall_peak_vals = []\n",
    "for channel, (ax, title) in enumerate(zip(axs.flatten(), rdf_data.channel.unique())):\n",
    "    result = []\n",
    "    for name, dat in rdf_data[rdf_data.channel == title].groupby([\"time\",])[\n",
    "        [\"radius\", \"intensity\"]\n",
    "    ]:\n",
    "        result.append(\n",
    "            {\n",
    "                \"com_radius\": np.average(\n",
    "                    dat[\"radius\"],\n",
    "                    weights=(dat[\"intensity\"] - dat[\"intensity\"].min())\n",
    "                    / (dat[\"intensity\"].max() - dat[\"intensity\"].min()),\n",
    "                ),\n",
    "                \"max_radius\": dat.loc[dat['intensity'].idxmax(), 'radius'],\n",
    "                \"time\": name,\n",
    "            }\n",
    "        )\n",
    "    peak_vals = pd.DataFrame.from_records(result)\n",
    "    overall_peak_vals.append(peak_vals.assign(channel=title))\n",
    "overall_peak_vals = pd.concat(overall_peak_vals, ignore_index=True)\n",
    "overall_peak_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66014002-a0de-4ba5-8837-4588fa0521ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=overall_peak_vals, x='time', y='com_radius', col='channel', col_wrap=2, kind='line', hue='channel')\n",
    "plt.subplots()\n",
    "sns.lineplot(data=overall_peak_vals, x='time', y='com_radius', hue='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc270e-e50b-44e3-8771-4e3e2edbeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate color bar\n",
    "def generate_color_bar(data, rgb, height=10, save_name=None, dist_to_peak=None):\n",
    "    result = np.zeros((height, len(data.radius.unique()), 3))\n",
    "\n",
    "    for output_ind, input_ind in enumerate(rgb):\n",
    "        to_plot = data[data.channel == input_ind].copy()\n",
    "        intens = to_plot.groupby(\"radius\")[\"intensity\"].mean()\n",
    "        result[:, ..., output_ind] = (intens - intens.min()) / (\n",
    "            intens.max() - intens.min()\n",
    "        )\n",
    "\n",
    "    # enhance color bar to show regions of difference between phases\n",
    "    # effectively set intersection of phases to 0 and clip negative\n",
    "    # subtract FC signal (green)\n",
    "    result[:, :, 0] -= result[:, :, 1]\n",
    "    result[:, :, 2] -= result[:, :, 1]\n",
    "\n",
    "    # subtract DFC signal (red)\n",
    "    result[:, :, 1] -= result[:, :, 0]\n",
    "    result[:, :, 2] -= result[:, :, 0]\n",
    "\n",
    "    # clip and rescale\n",
    "    result = np.clip(result, 0, 1)\n",
    "    result /= result.max(axis=(0, 1), keepdims=True)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(result, aspect=\"equal\")\n",
    "    plt.tick_params(left=False, labelleft=False)\n",
    "\n",
    "    ax.set_xlabel('Radius (px)')\n",
    "    \n",
    "    if dist_to_peak is not None:\n",
    "        t_labels = dist_to_peak.time\n",
    "        t_pixels = dist_to_peak.max_radius\n",
    "        ax_t = ax.secondary_xaxis('top')\n",
    "        ax_t.set_xticks(t_pixels)\n",
    "        ax_t.set_xticklabels(t_labels)\n",
    "        ax_t.set_xlabel('Time (min)')\n",
    "\n",
    "    # find intersections\n",
    "    r,g,b = result[0].T\n",
    "    \n",
    "    valid_idx = np.where(r >= 0.2)[0]\n",
    "    fc_dfc = valid_idx[abs(r[valid_idx] - g[valid_idx]).argmin()]\n",
    "    ax.axvline(fc_dfc, c='k', linestyle='--')\n",
    "    dfc_gc = valid_idx[abs(r[valid_idx] - b[valid_idx]).argmin()]\n",
    "    ax.axvline(dfc_gc, c='k', linestyle='--')\n",
    "    \n",
    "    print(intens.index[fc_dfc], intens.index[dfc_gc])\n",
    "    \n",
    "    if save_name:\n",
    "        plt.savefig(save_name)\n",
    "\n",
    "\n",
    "generate_color_bar(\n",
    "    data=rdf_data,\n",
    "    rgb=('DFC', 'FC', 'GC'),\n",
    "    # sample number of times to prevent overlap\n",
    "    dist_to_peak=overall_peak_vals[overall_peak_vals.time.isin((0, 30, 45, 60, 120)) & (overall_peak_vals.channel == 'EU')],\n",
    "    # save_name=\"linear_distance_remap.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176be8a-6fb7-4067-b8bb-8b947d1a91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate color bar\n",
    "def generate_color_bar_linearT(data, dist_to_peak, rgb, height=10, save_name=None):\n",
    "    result = np.zeros((height, dist_to_peak.time.max()+1, 3))\n",
    "    \n",
    "    interp_dists = np.interp(x=np.arange(0, dist_to_peak.time.max()+1),\n",
    "                             xp=dist_to_peak.time, fp=dist_to_peak.max_radius)\n",
    "    \n",
    "    dist_to_time = (np.abs(data.radius.unique() - interp_dists[:, None])).argmin(axis=1)\n",
    "    \n",
    "    for output_ind, input_ind in enumerate(rgb):\n",
    "        to_plot = data[data.channel == input_ind].copy()\n",
    "        intens = to_plot.groupby(\"radius\")[\"intensity\"].mean()\n",
    "        intens = (intens - intens.min()) / (\n",
    "            intens.max() - intens.min()\n",
    "        )\n",
    "        result[:, ..., output_ind] = intens.iloc[dist_to_time]\n",
    "            \n",
    "    result[:, :, 0] -= result[:, :, 1]\n",
    "    result[:, :, 2] -= result[:, :, 1]\n",
    "\n",
    "    result[:, :, 1] -= result[:, :, 0]\n",
    "    result[:, :, 2] -= result[:, :, 0]\n",
    "\n",
    "    result = np.clip(result, 0, 1)\n",
    "    result /= result.max(axis=(0, 1), keepdims=True)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(result, aspect=\"equal\")\n",
    "    plt.tick_params(left=False, labelleft=False)\n",
    "    \n",
    "    time_ticks = np.linspace(0, dist_to_peak.time.max(), 7)\n",
    "    ax.set_xticks(time_ticks)\n",
    "    ax.set_xlabel('Time (min)')\n",
    "    \n",
    "    ax_t = ax.secondary_xaxis('top')\n",
    "    ax_t.set_xticks(time_ticks)\n",
    "    \n",
    "    dist_labels = np.interp(x=time_ticks, xp=dist_to_peak.time, fp=dist_to_peak.max_radius).round(3)\n",
    "    ax_t.set_xticklabels(dist_labels)\n",
    "    ax_t.set_xlabel('Distance (px)')\n",
    "\n",
    "    # find intersections\n",
    "    r,g,b = result[0].T\n",
    "    \n",
    "    valid_idx = np.where(r >= 0.2)[0]\n",
    "    fc_dfc = valid_idx[abs(r[valid_idx] - g[valid_idx]).argmin()]\n",
    "    ax.axvline(fc_dfc, c='k', linestyle='--')\n",
    "    dfc_gc = valid_idx[abs(r[valid_idx] - b[valid_idx]).argmin()]\n",
    "    ax.axvline(dfc_gc, c='k', linestyle='--')\n",
    "    print(interp_dists[fc_dfc], interp_dists[dfc_gc])\n",
    "    time_pos = np.arange(dist_to_peak.Chase.max())\n",
    "    print(time_pos[fc_dfc], time_pos[dfc_gc])\n",
    "    \n",
    "    if save_name:\n",
    "        # imageio.imwrite(save_name, np.uint8(result * 255))\n",
    "        plt.savefig(save_name)\n",
    "\n",
    "\n",
    "generate_color_bar_linearT(\n",
    "    data=rdf_data,  # show a subset\n",
    "    dist_to_peak=overall_peak_vals[(overall_peak_vals.channel == 'EU')],\n",
    "    rgb=('DFC', 'FC', 'GC'),\n",
    "    # save_name=\"linear_time_remap.pdf\",  # save as a png to recolor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c750084-48b2-424e-bc01-274ac0afdc03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
