{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a28cd-0c97-4249-be9c-2c81d26eec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66618d-99d1-47f6-912f-35fa5d4e8fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to add total intensity by multiplying the area with the intensity\n",
    "def add_total_intens(df, channels, name):\n",
    "    if isinstance(channels, str):\n",
    "        channels = [channels]\n",
    "    for channel in channels:\n",
    "        df[f'total_intens_{channel}_{name}'] = df[f'Intensity_MeanIntensity_{channel}'] * df['AreaShape_Area']\n",
    "    return df\n",
    "\n",
    "# helper function to merge incoming dfs with the results by image number and cell number.  Can change reduction to be count, sum, etc.\n",
    "# map cols renames the columns from the input to output DFs\n",
    "def merge_reduced(result_df, df, map_cols, reduction, how='inner'):\n",
    "    return result_df.merge(\n",
    "        df.groupby(['ImageNumber', 'Parent_DilatedGC'])[list(map_cols.keys())].aggregate(reduction).reset_index().rename(columns=map_cols),\n",
    "        on=['ImageNumber', 'Parent_DilatedGC'],\n",
    "        how=how,\n",
    "    )\n",
    "\n",
    "def build_initial_data(directory, common, regex):\n",
    "    gc = pd.read_csv(\n",
    "        directory / 'InitialGC.csv', \n",
    "        usecols=common,\n",
    "    )\n",
    "    \n",
    "    # read image metadata, mainly file location\n",
    "    images = pd.read_csv(directory / 'Image.csv', usecols=['Metadata_FileLocation', 'ImageNumber', 'Metadata_Series'])\n",
    "    \n",
    "    # add in regex of filename (time, treatment, etc)\n",
    "    if regex:\n",
    "        images = images.join(images['Metadata_FileLocation'].str.extract(regex))\n",
    "    \n",
    "    # start building the final result, with image number and merged_gc number (renamed to cell number)\n",
    "    result = gc[['ImageNumber', 'Parent_DilatedGC']].drop_duplicates().rename(columns={\n",
    "        'Parent_DilatedGC': 'CellNumber'\n",
    "    })\n",
    "    \n",
    "    # add image file location and regex info\n",
    "    result = result.merge(images, on='ImageNumber', how=\"left\")\n",
    "    \n",
    "    # gc number, done separately because the cellnumber doesn't match parent_DilatedGC any more\n",
    "    result = result.merge(\n",
    "        gc.groupby(['ImageNumber', 'Parent_DilatedGC'])['AreaShape_Area'].count().rename('Count_GC').reset_index(),\n",
    "        left_on=['ImageNumber', 'CellNumber'], right_on=['ImageNumber', 'Parent_DilatedGC']\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_initial_gc(result, directory, common, dfc_intens=False):\n",
    "    # read GC, plus intensities for GC and Probe and eccentricity\n",
    "    gc = pd.read_csv(\n",
    "        directory / 'InitialGC.csv', \n",
    "        usecols=common + ['Intensity_MeanIntensity_GC', 'Intensity_MeanIntensity_Probe', \n",
    "                          'AreaShape_Eccentricity', 'AreaShape_Perimeter',\n",
    "                          'Location_CenterMassIntensity_X_GC',  'Location_CenterMassIntensity_Y_GC',\n",
    "                         ] + (['Intensity_MeanIntensity_DFC',] if dfc_intens else []),\n",
    "    )\n",
    "    \n",
    "    # gc intensity in gc  -> may not be the same, normalize to control in each folder\n",
    "    gc = add_total_intens(gc, ['GC', 'Probe']+ (['DFC',] if dfc_intens else []), 'GC')\n",
    "    \n",
    "    # calculate circularity as 4 pi area / perimeter ** 2\n",
    "    gc['AreaShape_Cicularity'] = 4 * np.pi * gc['AreaShape_Area'] / gc['AreaShape_Perimeter'] ** 2\n",
    "    \n",
    "    # gc shape and size\n",
    "    map_cols = {\n",
    "        'AreaShape_Eccentricity': 'mean_GC_eccentricity',\n",
    "        'AreaShape_Cicularity': 'mean_GC_circularity',\n",
    "        'Location_CenterMassIntensity_X_GC': 'center_x',\n",
    "        'Location_CenterMassIntensity_Y_GC': 'center_y',\n",
    "    }\n",
    "    result = merge_reduced(result, gc, map_cols, 'mean')\n",
    "    map_cols = {\n",
    "        'total_intens_GC_GC': 'total_GC_intens',\n",
    "        'total_intens_Probe_GC': 'total_Probe_intens_GC',\n",
    "        'AreaShape_Area': 'GC_area',\n",
    "    }\n",
    "    if dfc_intens:\n",
    "        map_cols['total_intens_DFC_GC'] = 'total_DFC_intens_GC'\n",
    "    result = merge_reduced(result, gc, map_cols, 'sum')\n",
    "    result['mean_mean_GC_intens'] = result['total_GC_intens']/ result['GC_area']\n",
    "    result['mean_mean_Probe_intens'] = result['total_Probe_intens_GC']/ result['GC_area']\n",
    "    if dfc_intens:\n",
    "        result['mean_mean_DFC_intens'] = result['total_DFC_intens_GC']/ result['GC_area']\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_initial_fc(result, directory, common):\n",
    "    # read FC intensities, positions (not used yet) and number of children in each region.\n",
    "    fc = pd.read_csv(\n",
    "        directory / 'InitialFC.csv', \n",
    "        usecols=common + ['Intensity_MeanIntensity_FC', 'Intensity_MeanIntensity_Probe', \n",
    "                          'Location_CenterMassIntensity_X_FC', 'Location_CenterMassIntensity_Y_FC',],\n",
    "    )\n",
    "    \n",
    "    # fc intensity in fc\n",
    "    # size of fc\n",
    "    fc = add_total_intens(fc, ['FC', 'Probe'], 'FC')\n",
    "\n",
    "    # add fcs total\n",
    "    result = merge_reduced(result, fc, {\"AreaShape_Area\": \"Count_FC\"}, 'count')\n",
    "    \n",
    "    map_cols = {\n",
    "        'total_intens_FC_FC': 'total_FC_intens',\n",
    "        'total_intens_FC_FC': 'total_Probe_intens_FC',\n",
    "        'AreaShape_Area': 'FC_area',\n",
    "    }\n",
    "    result = merge_reduced(result, fc, map_cols, 'sum')\n",
    "    result['FC_density'] = result['Count_FC']/ result['GC_area']\n",
    "\n",
    "    # add fcs outside of GC\n",
    "    fc = pd.read_csv(\n",
    "        directory / 'ExtraNucleolarFCs.csv', \n",
    "        usecols=common,\n",
    "    )\n",
    "    result = merge_reduced(result, fc, {\"AreaShape_Area\": \"Count_Nucleoplasmic_FC\"}, 'count', how='left')\n",
    "    result.loc[result['Count_Nucleoplasmic_FC'].isna(), 'Count_Nucleoplasmic_FC'] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_rim(result, directory, common, dfc, bins=1, total=10):\n",
    "    cols = open(directory / 'InitialGC.csv').readline().split(',')\n",
    "    cols = [c for c in cols \n",
    "            if c.startswith('RadialDistribution_FracAtD')\n",
    "            # or c.startswith('RadialDistribution_MeanFrac')\n",
    "           ]\n",
    "    distributions = pd.read_csv(\n",
    "        directory / 'InitialGC.csv', \n",
    "        usecols=common + (cols if dfc else [c for c in cols if 'DFC' not in c]),\n",
    "    )\n",
    "\n",
    "    bins = [i for i in range(total, total-bins, -1)]\n",
    "    relative_areas = distributions[[f'RadialDistribution_FracAtD_GCObjectImage_{bin}of{total}' for bin in bins]].sum(axis=1)\n",
    "    distributions['fc_rim_enrichment'] = distributions[[f'RadialDistribution_FracAtD_FC_{bin}of{total}' for bin in bins]].sum(axis=1) / relative_areas\n",
    "    if dfc:\n",
    "        distributions['dfc_rim_enrichment'] = distributions[[f'RadialDistribution_FracAtD_DFC_{bin}of{total}' for bin in bins]].sum(axis=1) / relative_areas\n",
    "\n",
    "    # print(dists[[f'RadialDistribution_MeanFrac_DFC_{bin}of10' for bin in bins]].sum(axis=1))\n",
    "    # print(relative_areas)\n",
    "        \n",
    "    map_cols = {\n",
    "        'fc_rim_enrichment': 'fc_rim_enrichment',\n",
    "        'dfc_rim_enrichment': 'dfc_rim_enrichment',\n",
    "    } if dfc else {'fc_rim_enrichment': 'fc_rim_enrichment'}\n",
    "    result = merge_reduced(result, distributions, map_cols, 'mean')\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_correlation(result, directory, common):\n",
    "    # correlations over combined regions\n",
    "    cols = open(directory / 'CombinedObjects.csv').readline().split(',')\n",
    "    cols = [c for c in cols \n",
    "            if c.startswith('Correlation_Correlation')\n",
    "            or c.startswith('Correlation_Overlap')\n",
    "           ]\n",
    "    corr = pd.read_csv(\n",
    "        directory / 'CombinedObjects.csv', \n",
    "        usecols=common + cols,\n",
    "    )\n",
    "    \n",
    "    # multiply all correlations by area\n",
    "    corr[cols] *= corr['AreaShape_Area'].to_numpy()[:, None]\n",
    "    \n",
    "    # sum and add to result\n",
    "    map_cols = {c: c[12:] for c in cols}\n",
    "    # map_cols = {c: c for c in cols}\n",
    "    map_cols['AreaShape_Area'] = 'combined_area'\n",
    "    result = merge_reduced(result, corr, map_cols, 'sum')\n",
    "    \n",
    "    # divide by total area for correlation\n",
    "    result[[c for c in map_cols.values() if c != 'combined_area']] /= result['combined_area'].to_numpy()[:, None]\n",
    "    return result\n",
    "    \n",
    "def read_data(directory, regex=None, dfc=True, bins=4, dfc_intens=False):\n",
    "    directory = Path(directory)\n",
    "    # image and object number are uniuqe identifiers.  Area is used a lot and the parent_mergedGC should corresopnd to a single cell\n",
    "    common = ['ImageNumber', 'ObjectNumber', 'AreaShape_Area', 'Parent_DilatedGC']\n",
    "\n",
    "    result = build_initial_data(directory, common, regex)\n",
    "    \n",
    "    result = add_initial_gc(result, directory, common, dfc_intens)\n",
    "    \n",
    "    result = add_initial_fc(result, directory, common)\n",
    "    \n",
    "    result = add_rim(result, directory, common, dfc, bins, total=20)\n",
    "    \n",
    "    result = add_correlation(result, directory, common)\n",
    "    \n",
    "    return result.drop(columns='Parent_DilatedGC')\n",
    "    # fc position (stringyness?, graph morphology of fcs)\n",
    "\n",
    "full_data = read_data('morphology/240820_FISH/outputs', r'/.*_10A_(?P<probe>[^_0]+)(?:\\d{3}\\d?)?.nd2', bins=4)\n",
    "full_data.loc[full_data.isna().any(axis=1), 'Metadata_FileLocation'].unique()\n",
    "full_data.probe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b2ee0-eff7-4e94-8b96-87dd8bb4e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'CX_EU'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FibKD', 'ctl'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "# sns.lineplot(data=df, x='time', y='RWC_FC_Probe', label='FC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_DFC_Probe', label='DFC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_GC_Probe', label='GC_Probe', style='treatment', legend=False)\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_CX.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23df8c-f476-4abd-8bde-49163889f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'Fib'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FibKD', 'ctl'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "# sns.lineplot(data=df, x='time', y='RWC_FC_Probe', label='FC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_DFC_Probe', label='DFC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_GC_Probe', label='GC_Probe', style='treatment', legend=False)\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_fib.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0826efe-267f-425a-863d-309ca3952c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'FVP_EU'].copy()\n",
    "# drop some data from another experiment...\n",
    "df = df[~df.time.isna()]\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FVP', 'DMSO'), ('-', 'dotted')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_fvp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66fd7a-abff-466c-974d-396df5e010c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'FVP_nodfc'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'DFC' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FVP2uM', 'DMSO'), ('-', 'dotted')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_fvp_nodfc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b8494-baf7-499f-beea-31a1c15cdce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'FVP_FISH'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['exp', 'treatment', 'time', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('FVP', 'DMSO'), ('-', 'dotted')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='probe')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='probe')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='probe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bcba2-140f-45ae-b2e8-d5876fc0f3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'RPL5'].copy()\n",
    "df['time'] = df['time'].astype(int)\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'time']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('RPL5KD', 'SCR'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='time', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "# sns.lineplot(data=df, x='time', y='RWC_FC_Probe', label='FC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_DFC_Probe', label='DFC_Probe', style='treatment', legend=False)\n",
    "# sns.lineplot(data=df, x='time', y='RWC_GC_Probe', label='GC_Probe', style='treatment', legend=False)\n",
    "sns.lineplot(data=df, x='time', y='Correlation_FC_Probe', label='FC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_DFC_Probe', label='DFC_Probe', style='treatment')\n",
    "sns.lineplot(data=df, x='time', y='Correlation_GC_Probe', label='GC_Probe', style='treatment')\n",
    "plt.savefig('EU_rpl5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e17f42-931c-4f42-a73d-b6d5e30c3075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.exp == 'RPL5_FISH'].copy()\n",
    "df\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "print(df.groupby(['treatment', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    for treatment, style in zip(('RPL5KD', 'SCR'), ('-', '--')):\n",
    "        sns.ecdfplot(data=df[df.treatment == treatment], x=col, hue='probe', linestyle=style, ax=ax, label=treatment)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "sns.barplot(data=df, x='probe', y='Correlation_FC_Probe', hue='treatment')\n",
    "plt.xticks(rotation=60)\n",
    "fig, axes = plt.subplots()\n",
    "sns.barplot(data=df, x='probe', y='Correlation_DFC_Probe', hue='treatment')\n",
    "plt.xticks(rotation=60)\n",
    "fig, axes = plt.subplots()\n",
    "sns.barplot(data=df, x='probe', y='Correlation_GC_Probe', hue='treatment')\n",
    "plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1c135-fc91-429d-b807-c171736b82fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.probe == 'U8FISH'].copy()\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          # and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "df = df[(df.mean_mean_Probe_intens < 0.002) | (df.treatment == 'SCR')]\n",
    "print(df.groupby(['exp', 'treatment', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='treatment', ax=ax)\n",
    "    \n",
    "fig, axes = plt.subplots()\n",
    "sns.ecdfplot(data=df[df.treatment != 'SCR'], x='mean_mean_Probe_intens', hue='treatment', ax=axes)\n",
    "axes.set_xlim(0, 0.0025)\n",
    "fig, axes = plt.subplots()\n",
    "# sns.kdeplot(data=df, x='dfc_rim_enrichment', hue='treatment', ax=axes)\n",
    "sns.ecdfplot(data=df, x='dfc_rim_enrichment', hue='treatment', ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeb102-a191-479d-9e2b-45bfd052d847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = full_data[full_data.probe == 'U3FISH'].copy()\n",
    "toplot = [c for c in df.columns[6:] \n",
    "          if not c.startswith('total') \n",
    "          and not c.startswith('center') \n",
    "          and not 'median' in c \n",
    "          # and not 'Probe' in c \n",
    "          and not c in ('treatement', 'time', 'probe', 'exp')\n",
    "         ]\n",
    "df = df[(df.mean_mean_Probe_intens < 0.005) | (df.treatment == 'SCR')]\n",
    "print(df.groupby(['exp', 'treatment', 'probe']).CellNumber.count())\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(toplot) / n_cols))\n",
    "\n",
    "figsize = (5*n_cols+5, 5*n_rows)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for col, ax in zip(toplot, axes.flatten()):\n",
    "    sns.ecdfplot(data=df, x=col, hue='treatment', ax=ax)\n",
    "    \n",
    "fig, axes = plt.subplots()\n",
    "sns.ecdfplot(data=df[df.treatment != 'SCR'], x='mean_mean_Probe_intens', hue='treatment', ax=axes)\n",
    "fig, axes = plt.subplots()\n",
    "sns.ecdfplot(data=df, x='fc_rim_enrichment', hue='treatment', ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493ca88-410e-4f71-906b-7cae6c965986",
   "metadata": {},
   "source": [
    "# CP RDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8d275-a90d-4db5-bfde-2a082a615f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rdf(result, directory, common):\n",
    "    cols = open(directory / 'InitialGC.csv', 'r').readline().split(',')\n",
    "    nucl = pd.read_csv(\n",
    "        directory / 'InitialGC.csv',\n",
    "        usecols=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC'] + [c.strip() for c in cols if c.startswith('RDF_')],\n",
    "        )\n",
    "    # intensity\n",
    "    nucl = nucl.melt(id_vars=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC'])\n",
    "    rdf = nucl[nucl.variable.str.startswith('RDF_Intensity')].reset_index(drop=True)\n",
    "    extract = rdf.variable.str.extract(r'RDF_Intensity_C(\\d)_R([-0-9]+)')\n",
    "    rdf = rdf.assign(\n",
    "        channel=extract[0].astype(int),\n",
    "        radius=extract[1].astype(int),\n",
    "    ).rename(columns={'value': 'intensity'}).drop(columns='variable')\n",
    "\n",
    "    counts = nucl[nucl.variable.str.startswith('RDF_Count')].reset_index(drop=True)\n",
    "    extract = counts.variable.str.extract(r'RDF_Counts_R([-0-9]+)')\n",
    "    counts = counts.assign(\n",
    "        radius=extract[0].astype(int)\n",
    "    ).rename(columns={'value': 'counts'}).drop(columns='variable')\n",
    "\n",
    "    rdf = rdf.merge(counts, on=['ImageNumber', 'ObjectNumber', 'Parent_DilatedGC', 'radius'])\n",
    "\n",
    "    return result, rdf\n",
    "\n",
    "def read_data(directory, regex=None, dfc=True, bins=4, dfc_intens=False):\n",
    "    directory = Path(directory)\n",
    "    # image and object number are uniuqe identifiers.  Area is used a lot and the parent_mergedGC should corresopnd to a single cell\n",
    "    common = ['ImageNumber', 'ObjectNumber', 'AreaShape_Area', 'Parent_DilatedGC']\n",
    "\n",
    "    result = build_initial_data(directory, common, regex)\n",
    "    \n",
    "    result = add_initial_gc(result, directory, common, dfc_intens)\n",
    "    \n",
    "    result = add_initial_fc(result, directory, common)\n",
    "    \n",
    "    result = add_rim(result, directory, common, dfc, bins, total=20)\n",
    "    \n",
    "    result = add_correlation(result, directory, common)\n",
    "\n",
    "    result, rdf = add_rdf(result, directory, common)\n",
    "    \n",
    "    return result.drop(columns='Parent_DilatedGC'), rdf\n",
    "\n",
    "data, rdf = read_data('morphology_rdf/RPL5/outputs/',  r'/[A-G]\\d+_(?P<treatment>SCR|RPL5KD)_15p(?P<time>\\d+)c.*nd2')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c070c-abec-44ef-a40a-823f79b44392",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59aa0a2-a248-4585-8d5b-20f35c40609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to average GCs from each parent\n",
    "rdf_avg = []\n",
    "groups = ['ImageNumber', 'Parent_DilatedGC', 'channel', 'radius']\n",
    "for name, dat in rdf.groupby(groups):\n",
    "    rdf_avg.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        counts=dat['counts'].sum(),\n",
    "    ))\n",
    "rdf_avg = pd.DataFrame(rdf_avg)\n",
    "rdf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e37218-98af-4d1a-8653-d0e6b084f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rdf_avg = pd.DataFrame(rdf_avg)\n",
    "rdf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ce410-3831-4091-9607-a38be125d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell information\n",
    "merged = rdf_avg.merge(data[['ImageNumber', 'CellNumber', 'time', 'treatment']], \n",
    "                   left_on=['ImageNumber', 'Parent_DilatedGC'], \n",
    "                   right_on=['ImageNumber', 'CellNumber'])\n",
    "# average raw values based on target and ssu\n",
    "groups = ['time', 'treatment', 'channel', 'radius']\n",
    "channels = ['', 'EU', 'DFC', 'FC', 'GC']\n",
    "rdf_data = []\n",
    "for name, dat in merged.groupby(groups):\n",
    "    rdf_data.append(dict(\n",
    "        zip(groups, name),\n",
    "        intensity=((dat['intensity'] * dat['counts']).fillna(0).sum()) / dat['counts'].sum(),\n",
    "        channel=channels[name[2]]\n",
    "    ))\n",
    "rdf_data = pd.DataFrame(rdf_data)  \n",
    "rdf_data['time'] = rdf_data.time.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83122a70-41c0-477f-aca6-692d58e080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=rdf_data, x='radius', y='intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e547219-d395-44ae-ad5d-380fd467e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = rdf_data.copy()\n",
    "normalized['normalized_intensity'] = normalized.groupby(['channel', 'treatment', 'time']).intensity.transform(lambda x: (x - x.min()) / (x.max() - x.min()), )\n",
    "sns.relplot(data=normalized, x='radius', y='normalized_intensity', col='channel', \n",
    "            kind='line', style='treatment', hue='time', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ca50d-8e97-411f-9f51-ff7c144b735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=normalized, x='radius', y='normalized_intensity', col='time', col_wrap=3,\n",
    "            kind='line', style='treatment', hue='channel', facet_kws=dict(sharex=True, sharey=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82e809-6db1-4d7d-81f1-ec0d13001038",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized.to_csv('rpl5_rdf_cp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
